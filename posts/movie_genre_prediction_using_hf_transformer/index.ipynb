{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dc03c028-72be-41b4-9911-5ae2edc6e2f6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Movie Genre Predictions with Hugging Face Transformers\"\n",
    "description: \"My attempt on the Movie Genre Predictions competition\"\n",
    "author: \"Anubhav Maity\"\n",
    "date: \"09/06/2023\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cda271-48b9-497e-b019-454d8e6e2da7",
   "metadata": {},
   "source": [
    "# Movie Genre Predictions with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e98db-5a17-4807-b4f4-8957e22a0ef7",
   "metadata": {},
   "source": [
    "Install the following packages by uncommenting the following if not installed already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "039253e3-9407-4fa1-bcc8-0d7849084cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers -U\n",
    "# !pip install huggingface_hub\n",
    "# !pip install rich\n",
    "# !pip install accelerate -U\n",
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388328a-6fca-4644-b669-a4993bbad10c",
   "metadata": {},
   "source": [
    "Following are the steps to create hugging face credentials token which be needed when using `notebook_login` below\n",
    "\n",
    "1. **Create a Hugging Face account (if you don't have one)**: If you don't already have an account on the Hugging Face website, you'll need to create one. Visit the Hugging Face website (https://huggingface.co/) and sign up for an account.\n",
    "2. **Log in to your Hugging Face account**: Use your credentials to log in to your Hugging Face account.\n",
    "3. **Generate an API token**: Hugging Face provides API tokens for authentication. To generate an API token, go to your account settings on the Hugging Face website. You can usually find this in your account dashboard or profile settings.\n",
    "4. **Generate the token**: Once you're in your account settings, look for an option related to API tokens or credentials. You should find an option to generate a new token. Click on it, and the system will generate a unique API token for you.\n",
    "5. **Copy the API token**: Once the token is generated, you'll typically see it displayed on the screen. It might be a long string of characters. Copy this token to your clipboard.\n",
    "6. **Store the token securely**: API tokens are sensitive credentials, so it's essential to store them securely. You should never share your API token publicly or expose it in your code repositories.\n",
    "\n",
    "Now, you have your Hugging Face API token, which you can use for authentication when making requests to the Hugging Face API or accessing resources on the Hugging Face Model Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed975a61-db6a-434e-ad0a-968f44999d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35123681e1414ee1baa54df67ba8c4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063f07e-a3a8-423f-ae8c-157600970fe1",
   "metadata": {},
   "source": [
    "Lets import the following pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "227a809e-ff69-4235-b171-9360edea2cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from rich import print\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027fd4d-a994-4040-8840-0b3372e166f0",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92901d05-e7eb-4bbd-a4a0-cdbadd550153",
   "metadata": {},
   "source": [
    "We will be using the `datadrivenscience/movie-genre-prediction` competition dataset for model training. You can read more about the competition [here](https://huggingface.co/spaces/competitions/movie-genre-prediction) and the dataset [here](https://huggingface.co/datasets/datadrivenscience/movie-genre-prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4111ad0-371c-4f2e-a13e-22435c6a493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cc7caee3c848f99162d8fadd2d9dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387027bc2c044c148da7116d5f5b7a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9369da433a481f9c648bc4ea4cd3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fec8450fa546a0b8b023f4c2335d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.74M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf6f82d7da4e38881834524ec43285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7be4e6ae6f244918fd7a5f8bd269bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/54000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f17bae5acbb4805bff85f86fd0020bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'genre'],\n",
       "        num_rows: 54000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'genre'],\n",
       "        num_rows: 36000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"datadrivenscience/movie-genre-prediction\"); dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974a7f0-2068-4094-9c42-789ac8e93b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "The dataset has `train` and `test` splits with following features\n",
    "- id\n",
    "- movie name\n",
    "- synopsis\n",
    "- genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdc19ca-295a-40bb-9b24-5900639fe8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44978</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50185</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34131</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'movie_name'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Super Me'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Entity Project'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Behavioral Family Therapy for Serious Psychiatric Disorders'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'synopsis'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'A young scriptwriter starts bringing valuable objects back from his short nightmares of being chased by a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">demon. Selling them makes him rich.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'A director and her friends renting a haunted house to capture paranormal events in order to prove it and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">become popular.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'This is an educational video for families and family therapists that describes the Behavioral Family </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Therapy approach to dealing with serious psychiatric illnesses.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'genre'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'fantasy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'horror'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'family'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m44978\u001b[0m, \u001b[1;36m50185\u001b[0m, \u001b[1;36m34131\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'movie_name'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Super Me'\u001b[0m, \u001b[32m'Entity Project'\u001b[0m, \u001b[32m'Behavioral Family Therapy for Serious Psychiatric Disorders'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'synopsis'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'A young scriptwriter starts bringing valuable objects back from his short nightmares of being chased by a \u001b[0m\n",
       "\u001b[32mdemon. Selling them makes him rich.'\u001b[0m,\n",
       "        \u001b[32m'A director and her friends renting a haunted house to capture paranormal events in order to prove it and \u001b[0m\n",
       "\u001b[32mbecome popular.'\u001b[0m,\n",
       "        \u001b[32m'This is an educational video for families and family therapists that describes the Behavioral Family \u001b[0m\n",
       "\u001b[32mTherapy approach to dealing with serious psychiatric illnesses.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'genre'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'fantasy'\u001b[0m, \u001b[32m'horror'\u001b[0m, \u001b[32m'family'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset['train'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a6604-cdd8-493e-b196-06e400acbf00",
   "metadata": {},
   "source": [
    "Above we have sliced and printed 3 rows of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e4f0843-8e88-44ef-880f-0c91c0385ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action',\n",
       " 'adventure',\n",
       " 'crime',\n",
       " 'family',\n",
       " 'fantasy',\n",
       " 'horror',\n",
       " 'mystery',\n",
       " 'romance',\n",
       " 'scifi',\n",
       " 'thriller'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set(dataset['train']['genre'])\n",
    "num_labels = len(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb75f7-98f4-49e6-80f9-8c107c7fe106",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are 10 genres, \n",
    "- action\n",
    "- adventure\n",
    "- crime\n",
    "- family\n",
    "- fantasy\n",
    "- horror\n",
    "- mystery\n",
    "- romance\n",
    "- scifi\n",
    "- thriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61271746-95a6-42d8-958c-8f29ce69178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Counter</span><span style=\"font-weight: bold\">({</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fantasy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'horror'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'family'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'scifi'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'action'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'crime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'adventure'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'mystery'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'romance'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'thriller'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5400</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCounter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'fantasy'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'horror'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'family'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'scifi'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'action'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'crime'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'adventure'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'mystery'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'romance'\u001b[0m: \u001b[1;36m5400\u001b[0m,\n",
       "    \u001b[32m'thriller'\u001b[0m: \u001b[1;36m5400\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_count = Counter(dataset['train']['genre']); print(labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef086ba3-e499-4930-891c-820f33d7b4d6",
   "metadata": {},
   "source": [
    "Looks like the labels are evenly sampled, everyone has count of 5400. Thats good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888d1e3-9a72-4d16-a61a-0c012f3c7dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "191d778a-5c9a-41d2-973e-345ec99153c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c8069-2c10-49f9-b4b0-125769b814b9",
   "metadata": {},
   "source": [
    "A checkpoint is a saved model state, including its architecture and trained weights, which can be used for various NLP tasks and fine-tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a07961a0-36c3-4706-b3f2-78ccdb764dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3185, 6907, 20932, 2007, 17662, 2227, 19081, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer('Movie Genre Predictions with Hugging Face Transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b364ac8-fb89-4d9c-907e-3d428fbd6f27",
   "metadata": {},
   "source": [
    "Above we load the tokenizer and use it on a sentence. Loading a checkpoint of a tokenizer associated with a pretrained language model is necessary to maintain consistency in the tokenization process. This ensures that your input text is processed in a way that aligns with the model's pre-existing knowledge and allows you to use the pretrained model effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0dbf02-bdba-457d-afc3-3804d5299444",
   "metadata": {},
   "source": [
    "What is `attention_mask`?\n",
    "> Sometimes, we want to tell the computer which parts of the sentence are important and which are not. The attention mask is like a spotlight. It's a list of 1s and 0s, where 1 means \"pay attention\" and 0 means \"ignore.\" For our sentence, it could be [1, 1, 1, 1, 1] because we want the computer to pay attention to all tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4d1b3-b31a-400a-b501-d49ec647db35",
   "metadata": {},
   "source": [
    "What is `token_type_ids`?\n",
    "> If you have multiple sentences, you'd want the computer to know which sentence each token belongs to. Token Type IDs help with that. For one sentence, it's all 0s. If you had two sentences, the first sentence would have 0s, and the second sentence would have 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36bc3d-717f-4a6f-a673-5fbf71b5bba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's break down the process of creating `input_ids` below into following steps:\n",
    "\n",
    "#### 1. Tokenize: \n",
    "\n",
    "Imagine you have a sentence, \"Hugging Face is awesome!\" To help a computer understand it, you first split it into smaller parts, like words: [\"Hugging\", \"Face\", \"is\", \"awesome\", \"!\"]. These smaller parts are called tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8500f2-8fd9-45d8-96c7-634edcb9c62a",
   "metadata": {},
   "source": [
    "We can tokenize the synopsis of the first row of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16cf025f-f925-4b7b-97bf-33bee28be2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A young scriptwriter starts bringing valuable objects back from his short nightmares of being chased by a demon. Selling them makes him rich.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['synopsis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23da130b-c383-4b9a-aaa9-8190384ea62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'young',\n",
       " 'script',\n",
       " '##writer',\n",
       " 'starts',\n",
       " 'bringing',\n",
       " 'valuable',\n",
       " 'objects',\n",
       " 'back',\n",
       " 'from',\n",
       " 'his',\n",
       " 'short',\n",
       " 'nightmares',\n",
       " 'of',\n",
       " 'being',\n",
       " 'chased',\n",
       " 'by',\n",
       " 'a',\n",
       " 'demon',\n",
       " '.',\n",
       " 'selling',\n",
       " 'them',\n",
       " 'makes',\n",
       " 'him',\n",
       " 'rich',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(dataset['train'][0]['synopsis']); tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ace5a4-6b73-46b4-bc9f-f2aa6934431d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Conversion to IDs: \n",
    "\n",
    "Computers prefer numbers, so we need to convert these tokens into unique numbers. Each token gets a special ID. For example, \"Hugging\" might be ID 101, \"Face\" might be ID 102, and so on. The sentence becomes a list of IDs: [101, 102, 103, 104, 105]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ba066a-0b8a-4130-933a-19b2aaa04416",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1037,\n",
       " 2402,\n",
       " 5896,\n",
       " 15994,\n",
       " 4627,\n",
       " 5026,\n",
       " 7070,\n",
       " 5200,\n",
       " 2067,\n",
       " 2013,\n",
       " 2010,\n",
       " 2460,\n",
       " 15446,\n",
       " 1997,\n",
       " 2108,\n",
       " 13303,\n",
       " 2011,\n",
       " 1037,\n",
       " 5698,\n",
       " 1012,\n",
       " 4855,\n",
       " 2068,\n",
       " 3084,\n",
       " 2032,\n",
       " 4138,\n",
       " 1012]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens); ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f133c74-2f80-429e-a134-464f97627736",
   "metadata": {},
   "source": [
    "In summary, Hugging Face tokenization takes your text, breaks it into tokens (smaller parts), gives each token a unique ID, creates an attention mask to say what's important, and token type IDs to track different sentences if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9831a847-dade-4c27-93f4-32c0841b17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column('genre', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b649897d-47ef-45eb-8bef-f002e943fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fd1857c7f64e54abad1fd5519c12a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/54000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407882e815264819896a6ab1a933f9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.class_encode_column(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bda7613e-36d2-4134-9f6e-779e17a26e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset[\"train\"].train_test_split(test_size=0.2, stratify_by_column=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6d1b3a6f-ce9f-46a6-b7c4-6c2fc8479e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'labels'],\n",
       "        num_rows: 43200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'labels'],\n",
       "        num_rows: 10800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a28e84e-15cd-4053-87fd-4bfac60cf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    sample[\"labels\"] = dataset[\"train\"].features[\"labels\"].str2int(sample[\"labels\"])\n",
    "    return tokenizer(sample['synopsis'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e4bb7ff0-0c25-4d4b-9956-a18a1e5d424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 43200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'movie_name', 'synopsis', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(tokenize, batched=True); tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d6484d8-ae39-4d0d-bb63-948cecfbeed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b969c4ebeffd4bca9847da6b2bc5e239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'movie_name', 'synopsis', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36000\n",
       "})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_ds = dataset[\"test\"].map(tokenize, batched=True); tokenized_test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccee7d8-e57c-4ff7-9b34-641c9d690f63",
   "metadata": {},
   "source": [
    "The above code tokenizes the dataset's `synopsis` feature using the tokenize function in a batch wise manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f286be-753a-4952-a8b1-b57535b6279e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "604d8042-3dc8-4446-ac90-49c96fae0bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments('movie-genre-predictions', \n",
    "                                  evaluation_strategy = 'epoch',\n",
    "                                  per_device_train_batch_size = 32,\n",
    "                                  per_device_eval_batch_size = 64,\n",
    "                                  save_strategy = 'epoch',\n",
    "                                  push_to_hub = True\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786fcbc-1430-4d60-9e56-2caffc2f7db8",
   "metadata": {},
   "source": [
    "The above code sets up the configuration for training a Hugging Face model, for a movie genre prediction task. Let's break it down step by step:\n",
    "\n",
    "1. `TrainingArguments`: This is a special object or data structure that holds various settings and options for training a machine learning model.\n",
    "\n",
    "2. `'movie-genre-predictions'`: It's naming the training process or giving it a unique name. It's like giving a name to a file so you can easily identify it later.\n",
    "\n",
    "3. `evaluation_strategy = 'epoch'`: This line specifies how often the model's performance should be evaluated. In this case, it's set to 'epoch,' which means after every complete pass through the training data. An epoch is like a full round of training.\n",
    "\n",
    "4. `per_device_train_batch_size = 32`: This indicates how many examples or data points should be processed at once on each  processing unit during training. It's set to 32, so 32 data points will be processed together in parallel.\n",
    "\n",
    "5. `per_device_eval_batch_size = 64`: Similar to the previous line, but this one specifies the batch size for evaluation (measuring how well the model is doing). It's set to 64, so 64 examples will be evaluated at once.\n",
    "\n",
    "6. `save_strategy = 'epoch'`: This determines when the model's checkpoints (saves of the model's progress) should be saved. Again, it's set to 'epoch,' meaning after each training round.\n",
    "\n",
    "7. `push_to_hub = True`: This is likely specific to the Hugging Face Transformers library. If set to 'True,' it means that the model checkpoints will be pushed or uploaded to the Hugging Face Model Hub, a place to store and share models.\n",
    "\n",
    "In simple terms, this code is configuring how a machine learning model should be trained for movie genre prediction. It sets up details like when to check how well the model is doing, how much data to process at a time, and where to save the model's progress. It also says that the model checkpoints should be uploaded to the Hugging Face Model Hub.\n",
    "\n",
    "You may see more details about `TrainingArguments` [here](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c0592780-f405-4279-bd5d-da570ed52d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9219e3-fd7a-44e9-aea6-cdb3900850a1",
   "metadata": {},
   "source": [
    "Above we load the model for `Sequence Classification` of 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "25a92a5b-0b66-4ef2-9c34-9938d7455bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e240a4-8fdc-4a68-9610-b9930f239aaa",
   "metadata": {},
   "source": [
    "The `evaluate` library provides the metrics on which to evaluate the validation set. Above I have choosen accuracy as the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "af4c62ac-82e6-47ff-9762-3f8d3da26182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(batch):\n",
    "    logits, labels = batch\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afcf7a-da47-445f-a3b4-7f92ed5fc9f0",
   "metadata": {},
   "source": [
    "I have defined `compute_metrics` to compute the metrics after each epoch on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f564fcb1-834d-44e6-8f8e-0a8dc8f953dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, \n",
    "                  args = training_args,\n",
    "                  train_dataset = tokenized_ds['train'],\n",
    "                  eval_dataset = tokenized_ds['test'], \n",
    "                  tokenizer = tokenizer,\n",
    "                  compute_metrics = compute_metrics\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81f0fd-3edd-4a89-952e-86f4f4ec2957",
   "metadata": {},
   "source": [
    "The `Trainer` function in Hugging Face simplifies the process of fine-tuning pre-trained NLP models for specific tasks. It handles data loading, training, evaluation, and model saving, making it easier to customize and use these models for various NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c05b6ab3-9ba1-4279-a4d9-ebed21fa5649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4050' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4050/4050 09:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>3.311370</td>\n",
       "      <td>0.317315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.029200</td>\n",
       "      <td>2.257011</td>\n",
       "      <td>0.325463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.676700</td>\n",
       "      <td>2.709101</td>\n",
       "      <td>0.312685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4050, training_loss=0.6523225073166835, metrics={'train_runtime': 562.6496, 'train_samples_per_second': 230.339, 'train_steps_per_second': 7.198, 'total_flos': 3860478233326848.0, 'train_loss': 0.6523225073166835, 'epoch': 3.0})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed534b6-5573-47eb-9a77-0af5f1f4619d",
   "metadata": {},
   "source": [
    "## Submitting to the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1aa98b8e-ddc1-45cd-abde-e0149951bd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_logits = trainer.predict(tokenized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e251bde-d37b-467f-9c45-bd11e12d7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 10)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logits.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aa38ef3f-4a77-4d51-abbd-66f8c0864917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.argmax(test_logits.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4393732b-a6de-4234-b80a-156a14cbcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_genre = dataset[\"train\"].features[\"labels\"].int2str(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a0545cfd-fb95-4de0-9320-dbd3b92c47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':tokenized_test_ds['id'],\n",
    "                  'genre': predicted_genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "28e653e7-4389-4f82-ba78-0089d9a6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1135df9-fc89-4219-877e-88913e2add11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
